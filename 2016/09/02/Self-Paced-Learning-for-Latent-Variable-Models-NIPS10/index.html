<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Self-Paced Learning for Latent Variable Models_NIPS10 | K_Augus</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="这一篇是Self-Paced Learning(SPL)的奠基之作。SPL，固名思义，就是一步步，有自主步伐节奏得学。Motivation应该来自于09年Bengio提出的Curriculum Learning(CL)。CL受到认知科学的启发——人在学东西的时候也没办法一下子接受特别困难的知识，是从简单的开始学起。所以CL是根据某种先验，将按照困难度排好序的样本逐渐喂给模型。SPL与CL最大的不同">
<meta property="og:type" content="article">
<meta property="og:title" content="Self-Paced Learning for Latent Variable Models_NIPS10">
<meta property="og:url" content="http://yoursite.com/2016/09/02/Self-Paced-Learning-for-Latent-Variable-Models-NIPS10/index.html">
<meta property="og:site_name" content="K_Augus">
<meta property="og:description" content="这一篇是Self-Paced Learning(SPL)的奠基之作。SPL，固名思义，就是一步步，有自主步伐节奏得学。Motivation应该来自于09年Bengio提出的Curriculum Learning(CL)。CL受到认知科学的启发——人在学东西的时候也没办法一下子接受特别困难的知识，是从简单的开始学起。所以CL是根据某种先验，将按照困难度排好序的样本逐渐喂给模型。SPL与CL最大的不同">
<meta property="og:image" content="http://yoursite.com/uploads/SPL.png">
<meta property="og:updated_time" content="2016-09-03T00:51:58.971Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Self-Paced Learning for Latent Variable Models_NIPS10">
<meta name="twitter:description" content="这一篇是Self-Paced Learning(SPL)的奠基之作。SPL，固名思义，就是一步步，有自主步伐节奏得学。Motivation应该来自于09年Bengio提出的Curriculum Learning(CL)。CL受到认知科学的启发——人在学东西的时候也没办法一下子接受特别困难的知识，是从简单的开始学起。所以CL是根据某种先验，将按照困难度排好序的样本逐渐喂给模型。SPL与CL最大的不同">
<meta name="twitter:image" content="http://yoursite.com/uploads/SPL.png">
  
    <link rel="alternate" href="/atom.xml" title="K_Augus" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">K_Augus</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Self-Paced-Learning-for-Latent-Variable-Models-NIPS10" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/02/Self-Paced-Learning-for-Latent-Variable-Models-NIPS10/" class="article-date">
  <time datetime="2016-09-02T14:14:38.000Z" itemprop="datePublished">2016-09-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/SelfPacedLearning/">SelfPacedLearning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Self-Paced Learning for Latent Variable Models_NIPS10
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这一篇是Self-Paced Learning(SPL)的奠基之作。<br>SPL，固名思义，就是一步步，有自主步伐节奏得学。Motivation应该来自于09年Bengio提出的Curriculum Learning(CL)。CL受到认知科学的启发——人在学东西的时候也没办法一下子接受特别困难的知识，是从简单的开始学起。所以CL是根据某种先验，将按照困难度排好序的样本逐渐喂给模型。SPL与CL最大的不同之处在于这个排样本的先验是嵌入到模型里面的，是动态的，可以优化学习的。<br>这样子从易到难得学可以看成是一种正则化的手段，有助于加快收敛，并达到一个更好的local minimum.</p>
<a id="more"></a>
<p>考虑一个普通的机器学习优化问题<br>\begin{equation}<br>w_{t+1}=argmin_{w\in R^d}\left(r(w)+\sum_{i=1}^nf(x_i, y_i; w)\right)<br>\end{equation}<br>$r(.)$是一个正则化项，$f(.)$就是loss项了，比如负对数似然函数。SPL需要考虑样本的难易程度，以及一次要用多少样本。所以这篇文章引入了一个binary variable $v_i$，表示这个样本是否是简单的样本，只有简单的样本才在目标函数中有贡献。这样子新的目标函数是一个混合整数规划【mixed-integer program】问题：<br>\begin{equation}<br>(w_{t+1}, v_{t+1})=argmin_{w\in R^d, v\in {0,1}^n}\left(r(w)+\sum_{i=1}^nv_if(x_i, y_i; w) - \frac{1}{K}\sum_{i=1}{n}v_i\right)<br>\end{equation}<br>$K$是用来调整要选多少简单的样本：当$K$比较大时，为了使目标函数更小，那么就只有$f(.)$比较小【high likelihood，因为是负的】的样本会被选中。<br>更重要的是，每个样本是否是简单的其实不是单独考虑的——它们之间通过参数$w$联系起来，也即，一组样本是简单的条件是有$w$能够拟合这组样本，得到一个值比较小的$f(.)$。<br>在训练过程中，我们逐渐减小$K$的值，使得越来越多的样本能够被考虑进来。当$K$趋近于0时，优化(2)其实就相当于在优化(1)。<br>然而(2)这样的混合整数规划问题通常不好求解，所以我们松弛对参数$v$的约束：允许$v_i$的值落在[0, 1]之间。这个松弛是紧的【tight】，也就是说，取得最优值的$w$，对应的每个$v_i$一定是0或1。这很好理解：如果$f(x_i,y_i;w)\lt 1/K$，那么肯定$v_i=1$能取得最小值；如果$f(x_i,y_i;w)\gt 1/K$，那么肯定$v_i=0$能取得最小值。<br>经过这样的松弛之后，问题就比较好解了。特殊情况下，如果$r(.)$和$f(.)$都是凸的，那么这个目标函数就是个biconvex的目标函数，可以采用诸如坐标下降的方法求解。作者用的是alternative convex search(ACS)。一般情况下，如果$r(.)$和$f(.)$都是非凸的，也可以用类似的方法求解：给定$w$，最优的$v$值为$v_i=\delta(f(x_i, y_i; w)\lt 1/K$，其中$\delta(.)$为指示函数【indicator function】；给定$v$，优化(2)就跟优化(1)一样。<br>作者在实验中$w$的初值是设置所有$v_i=1$，然后用CCCP算法跑一段时间。</p>
<p>最后用孟德宇老师的一页ppt总结一下SPL：<br><img src="/uploads/SPL.png" alt="SPL"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/02/Self-Paced-Learning-for-Latent-Variable-Models-NIPS10/" data-id="civn67raj000dy0cvv6758d9c" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Latent/">Latent</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NIPS/">NIPS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SelfPacedLearning/">SelfPacedLearning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/09/03/Expectation-Maximization-Algorithm/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Expectation Maximization Algorithm
        
      </div>
    </a>
  
  
    <a href="/2016/09/01/Domain-Adaptation-from-Multiple-Sources-via-Auxiliary-Classifiers-ICML09/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Domain Adaptation from Multiple Sources via Auxiliary Classifiers_ICML09</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/ModelCompression/">ModelCompression</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PaperNotes/">PaperNotes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/SelfPacedLearning/">SelfPacedLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/TransferLearning/">TransferLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tutorial/">Tutorial</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayesian/">Bayesian</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bilinear/">Bilinear</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DL/">DL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DepthMap/">DepthMap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EM/">EM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gaussian/">Gaussian</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICLR/">ICLR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICML/">ICML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Latent/">Latent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ModelCompression/">ModelCompression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NIPS/">NIPS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SelfPacedLearning/">SelfPacedLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transfer/">Transfer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tutorial/">Tutorial</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Bayesian/" style="font-size: 15px;">Bayesian</a> <a href="/tags/Bilinear/" style="font-size: 10px;">Bilinear</a> <a href="/tags/DL/" style="font-size: 10px;">DL</a> <a href="/tags/DepthMap/" style="font-size: 10px;">DepthMap</a> <a href="/tags/EM/" style="font-size: 10px;">EM</a> <a href="/tags/Gaussian/" style="font-size: 10px;">Gaussian</a> <a href="/tags/ICLR/" style="font-size: 10px;">ICLR</a> <a href="/tags/ICML/" style="font-size: 10px;">ICML</a> <a href="/tags/Latent/" style="font-size: 15px;">Latent</a> <a href="/tags/ModelCompression/" style="font-size: 10px;">ModelCompression</a> <a href="/tags/NIPS/" style="font-size: 20px;">NIPS</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/SelfPacedLearning/" style="font-size: 15px;">SelfPacedLearning</a> <a href="/tags/Transfer/" style="font-size: 20px;">Transfer</a> <a href="/tags/Tutorial/" style="font-size: 20px;">Tutorial</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/11/18/Auto-Encoding-Variational-Bayes-iclr14/">Auto-Encoding Variational Bayes_iclr14</a>
          </li>
        
          <li>
            <a href="/2016/09/17/Depth-Map-Prediction/">Depth Map Prediction</a>
          </li>
        
          <li>
            <a href="/2016/09/15/Gaussian-distribution/">Gaussian distribution</a>
          </li>
        
          <li>
            <a href="/2016/09/11/Distilling-the-Knowledge-in-a-Neural-Network/">Distilling the Knowledge in a Neural Network</a>
          </li>
        
          <li>
            <a href="/2016/09/10/Variational-Inference/">Variational Inference</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 K_Augus<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>