<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>K_Augus</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2016-09-04T14:10:12.813Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>K_Augus</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Self-Paced Learning with Diversity_NIPS14.md</title>
    <link href="http://yoursite.com/2016/09/04/Self-Paced-Learning-with-Diversity-NIPS14-md/"/>
    <id>http://yoursite.com/2016/09/04/Self-Paced-Learning-with-Diversity-NIPS14-md/</id>
    <published>2016-09-04T14:09:31.000Z</published>
    <updated>2016-09-04T14:10:12.813Z</updated>
    
    <content type="html"><![CDATA[<p>这一篇文章的思想其实很简单，就是让SPL在选择样本的时候不单单只考虑样本的难易程度，还要考虑样本的多样性。这个多样性通过group lasso的优化项来体现。</p>
<a id="more"></a>
<p>首先，我们的样本$X=(x_1,…,x_n) \in R^{m_n}$被分成$b$组：$X^{(1)},…,X^{(b)},X^{(j)}\in R^{m_n_j}$，$n_j$是第$j$组的样本数目；这个分组要么是给定的，要么可以用一些无监督的方法，比如聚类得到；相应的定义每个组的难易度系数向量$v=[v^{(1)},…,v^{(b)}],\ v^{(j)}=(v^{(j)}_1,…,v^{(j)}_{n_j})^T\in [0,1]^{n_j}$。这样子得到我们新的优化模型：<br>\begin{equation}<br>min_{w,v}E(w,v;\lambda, \gamma)=\sum_{i=1}^nv_iL(y_i,f(x_i,w))-\lambda\sum_{i=1}^nv_i-\gamma|v|_{2,1},\quad s.t. v\in[0,1]^n<br>\end{equation}<br>这里新引入的负$l_{2,1}-norm$项就是为了得到样本的多样性。具体得<br>$$-|v|_{2,1}=-\sum_{j=1}^b|v^{(j)}|_2$$<br>本来$l_{2,1}-norm$是为了得到组稀疏的，现在加了个负号，就能得到和组稀疏相反的效果，也即多样性。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一篇文章的思想其实很简单，就是让SPL在选择样本的时候不单单只考虑样本的难易程度，还要考虑样本的多样性。这个多样性通过group lasso的优化项来体现。&lt;/p&gt;
    
    </summary>
    
      <category term="SelfPacedLearning" scheme="http://yoursite.com/categories/SelfPacedLearning/"/>
    
    
      <category term="NIPS" scheme="http://yoursite.com/tags/NIPS/"/>
    
      <category term="SelfPacedLearning" scheme="http://yoursite.com/tags/SelfPacedLearning/"/>
    
  </entry>
  
  <entry>
    <title>Expectation Maximization Algorithm</title>
    <link href="http://yoursite.com/2016/09/03/Expectation-Maximization-Algorithm/"/>
    <id>http://yoursite.com/2016/09/03/Expectation-Maximization-Algorithm/</id>
    <published>2016-09-03T02:28:16.000Z</published>
    <updated>2016-09-03T02:31:21.213Z</updated>
    
    <content type="html"><![CDATA[<p>在机器学习的领域里面，我们常常需要用极大似然估计【或极大化后验】的方法去求解一个变量的值<br>\begin{equation}<br>\theta^{MLE}=argmax_{\theta}(\mathcal{L}(\theta))=argmax_{\theta}(ln[p(X|\theta)])<br>\end{equation}<br>然而，当模型中含有隐变量，或者说观测数据不完整时，用极大似然估计往往不能得到一个闭式解【closed-form solution】。EM算法就是一种求解这种含有隐变量模型的迭代算法。</p>
<a id="more"></a>
<p>我们用$Z$表示所有的隐变量，$X$表示所有的观察到的变量，$\Theta$表示所有的参数，则log likelihood可以写成：<br>\begin{align}<br>\mathcal{L}(\Theta|X) &amp; = ln(p(X|\Theta))\\<br>&amp;= ln\left(\frac{p(X,Z|\Theta)}{p(Z|X,\Theta)}\right) \\<br>&amp;= ln\left(\frac{p(X,Z|\Theta)}{Q(Z)}*\frac{Q(Z)}{p(Z|X,\Theta)}\right)\\<br>&amp;= ln\left(\frac{p(X,Z|\Theta)}{Q(Z)}\right)+ln\left(\frac{Q(Z)}{p(Z|X,\Theta)}\right)<br>\end{align}<br>两边对Q(Z)这个分布求期望，左边因为不含变量$Z$，所以不会影响：<br>\begin{align}<br>ln(p(X|\Theta)) &amp;= \int_ZQ(Z)ln\left(\frac{p(X,Z|\Theta)}{Q(Z)}\right)+\int_ZQ(Z)ln\left(\frac{Q(Z)}{p(Z|X,\Theta)}\right) \\<br>&amp;= \int_ZQ(Z)ln\left(\frac{p(X,Z|\Theta)}{Q(Z)}\right)+\underbrace{KL(Q(Z)||p(Z|X,\Theta))}_{\ge0} \\<br>&amp;= \mathcal{L}(\Theta,Q)  + KL(Q(Z)||p(Z|X,\Theta)) \\<br>&amp;\ge \mathcal{L}(\Theta,Q)<br>\end{align}<br>也即$L(\Theta,Q)$是$ln(p(X|\Theta))$的下界。引用PRML里的一幅图来形象说明它们之间的关系<br><img src="/uploads/EM.png" alt="EM"><br>所以EM其实是一个Maximize-Maximize的过程【$\Theta^{old}$表示上一次迭代$\Theta$的值】：</p>
<p><ul><b>在E步，我们固定住$\Theta^{old}$，优化下界【with respect to $Q(Z)$】，这时候下界最大当且仅当KL divergence为0，也即$Q(Z)=p(Z|X,\Theta^{old})$；</b></ul></p>
<p><ul><b>在M步，我们固定住$Q(Z)$，优化下界【with respect to $\Theta$】，得到$\Theta^{new}$</b></ul><br>这样子，每一步优化下界都在改进，所以EM一定会收敛，但是EM并不保证收敛到最优解<br>另一种证明$ln(p(X|\Theta))\ge F(\Theta, Z)$的方法是利用琴生不等式【Jensen’s Inequality】：<br>\begin{align}<br>ln(p(X|\Theta) &amp;= ln\int_Zp(X,Z|\Theta) \\<br>&amp;= \underbrace{ln\left(\int_Z\frac{p(X,Z|\Theta)}{Q(Z)}Q(Z)\right)}_{lnE_{Q(Z)}[f(Z)]} \\<br>&amp;\ge \underbrace{\int_Zln\left(\frac{p(X,Z|\Theta)}{Q(Z)}\right)Q(Z)}_{E_{Q(Z)}ln[f(Z)]}<br>\end{align}<br>接下来再讲一下M步里怎么优化下界，做完E步后KL divergence那一项变成0，即$Q(Z)=p(Z|X,\Theta^{old})$，所以<br>\begin{align}<br>\mathcal{L}(\Theta|X) &amp;= \mathcal{L}(\Theta, Q) \\<br>&amp;= \int_ZQ(Z)ln\left(\frac{p(X,Z|\Theta)}{Q(Z)}\right) \\<br>&amp;= \underbrace{\int_Zp(Z,X| \Theta^{old})ln(p(X,Z|\Theta))}_{Q(\Theta, \Theta^{old})}-\underbrace{\int_Zp(Z|X, \Theta^{old})ln(p(Z|X, \Theta^{old}))}_{independent\ of\ \Theta}<br>\end{align}<br>也就是我们只需要最大化$Q(\Theta, \Theta^{old})$<br>注意到现在我们要优化的参数$\Theta$只存在于log里面，如果分布$p(X,Z|\Theta)$是一个指数族分布，那么log和exp将会抵消，我们求解起来就会比原来直接求$p(X|\Theta)$简单得多<br>类似地，EM也可以用来做极大后验估计：<br>\begin{align}<br>ln(p(\Theta|X) &amp;= ln(p(\Theta,X))-ln(p(X)) \\<br>&amp;= ln(p(X|\Theta)) + ln(p(\Theta)) - ln(p(X))<br>\end{align}<br>对$ln(p(X|\Theta))$做和上面一样的分解即可</p>
<p></p><h2>“Tagare” approach</h2><br>另一种证明EM会收敛的方法，大同小异<br>\begin{align}<br>\mathcal{L}(\Theta|X) &amp;= ln(p(X|\Theta)) \\<br>&amp;= ln\left(\frac{p(X,Z|\Theta)}{p(Z|X,\Theta)}\right) \\<br>\end{align}<br>\begin{align}<br>&amp;\Rightarrow \int_zln(p(X|\Theta))p(Z|X, \Theta^{old}) \\<br>&amp;= \int_Zln(p(Z,X|\Theta))p(Z|X, \Theta^{old})dZ-\int_Zln(p(Z|X,\Theta))p(Z|X, \Theta^{old})dZ<br>\end{align}<br>\begin{align}<br>&amp;\Rightarrow ln(p(X|\Theta))\\<br>&amp;= \underbrace{\int_Zp(Z,X| \Theta^{old})ln(p(X,Z|\Theta))}_{Q(\Theta, \Theta^{old})}-\underbrace{\int_Zp(Z|X, \Theta^{old})ln(p(Z|X, \Theta))}_{H(\Theta, \Theta^{old})}<br>\end{align}<br>我们只maximize $Q(\Theta, \Theta^{old})$，因为可以证明<br>\begin{equation}<br>argmax_{\Theta}Q(\Theta, \Theta^{old})=\Theta^{new} \Rightarrow H(\Theta^{new}, \Theta^{old}) \le H(\Theta^{old}, \Theta^{old})<br>\end{equation}<br>这样子，我们就有<br>\begin{equation}<br>\mathcal{L}(\Theta^{new})=Q(\Theta^{new}, \Theta^{old})-H(\Theta^{new}, \Theta^{old}) \ge Q(\Theta^{old}, \Theta^{old})-H(\Theta^{old}, \Theta^{old}) = \mathcal{L}(\Theta^{old})<br>\end{equation}<br>可以用琴生不等式证明$H(\Theta^{old}, \Theta^{old})-H(\Theta, \Theta^{old}) \ge 0\quad \forall\Theta$<p></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在机器学习的领域里面，我们常常需要用极大似然估计【或极大化后验】的方法去求解一个变量的值&lt;br&gt;\begin{equation}&lt;br&gt;\theta^{MLE}=argmax_{\theta}(\mathcal{L}(\theta))=argmax_{\theta}(ln[p(X|\theta)])&lt;br&gt;\end{equation}&lt;br&gt;然而，当模型中含有隐变量，或者说观测数据不完整时，用极大似然估计往往不能得到一个闭式解【closed-form solution】。EM算法就是一种求解这种含有隐变量模型的迭代算法。&lt;/p&gt;
    
    </summary>
    
      <category term="Tutorial" scheme="http://yoursite.com/categories/Tutorial/"/>
    
    
      <category term="EM" scheme="http://yoursite.com/tags/EM/"/>
    
      <category term="Tutorial" scheme="http://yoursite.com/tags/Tutorial/"/>
    
      <category term="Latent" scheme="http://yoursite.com/tags/Latent/"/>
    
  </entry>
  
  <entry>
    <title>Self-Paced Learning for Latent Variable Models_NIPS10</title>
    <link href="http://yoursite.com/2016/09/02/Self-Paced-Learning-for-Latent-Variable-Models-NIPS10/"/>
    <id>http://yoursite.com/2016/09/02/Self-Paced-Learning-for-Latent-Variable-Models-NIPS10/</id>
    <published>2016-09-02T14:14:38.000Z</published>
    <updated>2016-09-03T00:51:58.971Z</updated>
    
    <content type="html"><![CDATA[<p>这一篇是Self-Paced Learning(SPL)的奠基之作。<br>SPL，固名思义，就是一步步，有自主步伐节奏得学。Motivation应该来自于09年Bengio提出的Curriculum Learning(CL)。CL受到认知科学的启发——人在学东西的时候也没办法一下子接受特别困难的知识，是从简单的开始学起。所以CL是根据某种先验，将按照困难度排好序的样本逐渐喂给模型。SPL与CL最大的不同之处在于这个排样本的先验是嵌入到模型里面的，是动态的，可以优化学习的。<br>这样子从易到难得学可以看成是一种正则化的手段，有助于加快收敛，并达到一个更好的local minimum.</p>
<a id="more"></a>
<p>考虑一个普通的机器学习优化问题<br>\begin{equation}<br>w_{t+1}=argmin_{w\in R^d}\left(r(w)+\sum_{i=1}^nf(x_i, y_i; w)\right)<br>\end{equation}<br>$r(.)$是一个正则化项，$f(.)$就是loss项了，比如负对数似然函数。SPL需要考虑样本的难易程度，以及一次要用多少样本。所以这篇文章引入了一个binary variable $v_i$，表示这个样本是否是简单的样本，只有简单的样本才在目标函数中有贡献。这样子新的目标函数是一个混合整数规划【mixed-integer program】问题：<br>\begin{equation}<br>(w_{t+1}, v_{t+1})=argmin_{w\in R^d, v\in {0,1}^n}\left(r(w)+\sum_{i=1}^nv_if(x_i, y_i; w) - \frac{1}{K}\sum_{i=1}{n}v_i\right)<br>\end{equation}<br>$K$是用来调整要选多少简单的样本：当$K$比较大时，为了使目标函数更小，那么就只有$f(.)$比较小【high likelihood，因为是负的】的样本会被选中。<br>更重要的是，每个样本是否是简单的其实不是单独考虑的——它们之间通过参数$w$联系起来，也即，一组样本是简单的条件是有$w$能够拟合这组样本，得到一个值比较小的$f(.)$。<br>在训练过程中，我们逐渐减小$K$的值，使得越来越多的样本能够被考虑进来。当$K$趋近于0时，优化(2)其实就相当于在优化(1)。<br>然而(2)这样的混合整数规划问题通常不好求解，所以我们松弛对参数$v$的约束：允许$v_i$的值落在[0, 1]之间。这个松弛是紧的【tight】，也就是说，取得最优值的$w$，对应的每个$v_i$一定是0或1。这很好理解：如果$f(x_i,y_i;w)\lt 1/K$，那么肯定$v_i=1$能取得最小值；如果$f(x_i,y_i;w)\gt 1/K$，那么肯定$v_i=0$能取得最小值。<br>经过这样的松弛之后，问题就比较好解了。特殊情况下，如果$r(.)$和$f(.)$都是凸的，那么这个目标函数就是个biconvex的目标函数，可以采用诸如坐标下降的方法求解。作者用的是alternative convex search(ACS)。一般情况下，如果$r(.)$和$f(.)$都是非凸的，也可以用类似的方法求解：给定$w$，最优的$v$值为$v_i=\delta(f(x_i, y_i; w)\lt 1/K$，其中$\delta(.)$为指示函数【indicator function】；给定$v$，优化(2)就跟优化(1)一样。<br>作者在实验中$w$的初值是设置所有$v_i=1$，然后用CCCP算法跑一段时间。</p>
<p>最后用孟德宇老师的一页ppt总结一下SPL：<br><img src="/uploads/SPL.png" alt="SPL"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一篇是Self-Paced Learning(SPL)的奠基之作。&lt;br&gt;SPL，固名思义，就是一步步，有自主步伐节奏得学。Motivation应该来自于09年Bengio提出的Curriculum Learning(CL)。CL受到认知科学的启发——人在学东西的时候也没办法一下子接受特别困难的知识，是从简单的开始学起。所以CL是根据某种先验，将按照困难度排好序的样本逐渐喂给模型。SPL与CL最大的不同之处在于这个排样本的先验是嵌入到模型里面的，是动态的，可以优化学习的。&lt;br&gt;这样子从易到难得学可以看成是一种正则化的手段，有助于加快收敛，并达到一个更好的local minimum.&lt;/p&gt;
    
    </summary>
    
      <category term="SelfPacedLearning" scheme="http://yoursite.com/categories/SelfPacedLearning/"/>
    
    
      <category term="NIPS" scheme="http://yoursite.com/tags/NIPS/"/>
    
      <category term="Latent" scheme="http://yoursite.com/tags/Latent/"/>
    
      <category term="SelfPacedLearning" scheme="http://yoursite.com/tags/SelfPacedLearning/"/>
    
  </entry>
  
  <entry>
    <title>Domain Adaptation from Multiple Sources via Auxiliary Classifiers_ICML09</title>
    <link href="http://yoursite.com/2016/09/01/Domain-Adaptation-from-Multiple-Sources-via-Auxiliary-Classifiers-ICML09/"/>
    <id>http://yoursite.com/2016/09/01/Domain-Adaptation-from-Multiple-Sources-via-Auxiliary-Classifiers-ICML09/</id>
    <published>2016-09-01T02:51:42.000Z</published>
    <updated>2016-09-01T03:10:24.971Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章做的是从多个源领域到单个目标领域的迁移，思想来源于Adaptive SVM[1]，就是使源领域模型参数“适应”到目标领域去。<br><a id="more"></a><br>假设现在有s个源领域$D^s=(x_i^s, y_i^s)|_{i=1}^{n_s}，s=1,2,…,P$，目标领域有标记数据$D_l^T=(x_i^T,y_i^T)|_{i=1}^{n_l}$和未标记数据$D_u^T=x_i^T|_{i=n_l+1}^{n_l+n_u}$，我们希望源领域的分类器$f^s(x)$和要学的目标领域分类器$f^T(x)$之间满足这样的关系：<br>\begin{equation}<br>f^T(x)=\sum_s\gamma_sf^s(x)+\Delta f(x)\\<br>s.t. \quad \sum_s\gamma_s=1<br>\end{equation}<br>扰动函数【perturbation function】$\Delta f(x)$用目标领域的标记数据$D_l^T$来学，根据[1]，<br>\begin{equation}<br>\Delta f(x)=\sum_{i=1}^{n_l}\alpha_i^Ty_i^Tk(x_i^T,x)<br>\end{equation}<br>类似地，<br>\begin{equation}<br>f^s(x)=\sum_s\gamma_s\sum_{i=1}^{n_s}\gamma_i^sy_i^sk(x_i^s,x)<br>\end{equation}<br>两者用相同的kernel<br>这样子，目标领域的分类器就变成了一些kernel的加权和<br>然而现在我们还没有考虑到怎么利用未标记的数据，根据manifold约束，在流形上相邻的特征它们的decision value也应该相近。因此作者认为，在domain adaption问题中，对于这些未标记的数据，目标分类器的decision value和与它比较相关的源领域分类器的decision value值也不应该差太远，所以作者提出了这样的一个data-dependent regularizer<br>\begin{equation}<br>\Omega_D(\textbf{f}_u^T)=\frac{1}{2}\sum_{i=n_l+1}^{n_T}\sum_s\gamma_s(f_i^T-f_i^s)^2=\frac{1}{2}\sum_s\gamma_s|\textbf{f}_u^T-\textbf{f}_u^s|^2<br>\end{equation}<br>$\gamma_s$表示目标领域与某个源领域之间的相关程度<br>$\textbf{f}_u^T=[f_{n_{l+1}}^T,…,f_{n_T}^T]’,\ \textbf{f}_u^s=[f_{n_{l+1}}^s, …, f_{n_T}^s]’$<br>所以最后的目标函数是<br>\begin{equation}<br>min_{f^T}\Omega(f^T)+\frac{1}{2}\sum_{i=1}^{n_l}(f_i^T-y_i^T)^2+\Omega_D(\textbf{f}_u^T)<br>\end{equation}<br>其中，$\Omega(f^T)$是目标分类器的参数正则化项<br>最后，作者还提出因为SVR【Support Vector Regression】通常能得到比较稀疏的解，所以还可以再加一个约束项<br>作者最后得出来的对偶形式也没有涉及太多的kernel运算，所以作者认为自己的算法比较scale</p>
<p>实验是在TRECVID 2005数据集上进行的</p>
<hr>
<p>[1] Crossdomain video concept detection using adaptive SVMs</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章做的是从多个源领域到单个目标领域的迁移，思想来源于Adaptive SVM[1]，就是使源领域模型参数“适应”到目标领域去。&lt;br&gt;
    
    </summary>
    
      <category term="TransferLearning" scheme="http://yoursite.com/categories/TransferLearning/"/>
    
    
      <category term="Transfer" scheme="http://yoursite.com/tags/Transfer/"/>
    
      <category term="SVM" scheme="http://yoursite.com/tags/SVM/"/>
    
      <category term="ICML" scheme="http://yoursite.com/tags/ICML/"/>
    
  </entry>
  
  <entry>
    <title>Bilinear classifiers for visual recognition_NIPS09</title>
    <link href="http://yoursite.com/2016/08/31/Bilinear-classifiers-for-visual-recognition-NIPS09/"/>
    <id>http://yoursite.com/2016/08/31/Bilinear-classifiers-for-visual-recognition-NIPS09/</id>
    <published>2016-08-31T11:39:59.000Z</published>
    <updated>2016-09-01T03:03:19.187Z</updated>
    
    <content type="html"><![CDATA[<p>Bilinear模型作为linear模型的泛化版本，一般是为了提升模型的表达能力，但是这篇文章是反过来的：作者把参数$W$分解为一些低秩矩阵，也即“因子”【factor】的积，进而减少参数数量，防止过拟合。<br><a id="more"></a><br>具体得说，原本线性SVM的模型是<br>\begin{equation} \label{eq:1}<br>L(W)=\frac{1}{2}Tr(W^TW)+C\sum_nmax(0,1-y_nTr(W^TX_n)<br>\end{equation}<br>$X \in R^{n_y*n_x*n_f}$, $n_y$和$n_x$是空间维度，$n_f$是特征维度。为简化讨论，下面固定$n_f=1$<br>通过对W进行低秩分解【这里的秩的约束通过$W_x$和$W_y$的秩不会超过$d$来体现】<br>\begin{equation}<br>W=W_yW^T_x,\ where\ \ W_y\in R^{n_y*d}, W_x\in R^{n_x*d}<br>\end{equation}<br>这样子对$W$进行分解后的Bilinear SVM可以重新写成<br>\begin{equation}<br>L_(W_y, W_x)=\frac{1}{2}Tr(W_xW_y^TW_yW_x^T)+C\sum_nmax(0, 1-y_nTr(W_xW_y^TX_n))<br>\end{equation}<br>然而这个形式不好优化，我们得把它写成像公式$\ref{eq:1}$的形式，即<br>\begin{equation}<br>L(\tilde{W}_y, W_x)=\frac{1}{2}Tr(\tilde{W}_y^T\tilde{W}_y)+C\sum_nmax(0,1-y_nTr(\tilde{W}_y^T\tilde{X}_n))\\<br>where\ \tilde{W}_y=W_yA^{\frac{1}{2}}, \tilde{X}_n=X_nW_xA^{-\frac{1}{2}}, A=W_x^TW_x<br>\end{equation}<br>这是一个biconvex的目标函数，可以用coordinate descent来解<br>如果现在有$M$个任务，每个任务都有不同的数据，那么我们限定所有的任务共享相同的参数空间，即<br>\begin{equation}<br>L(W)=\frac{1}{2}\sum_mTr(W^{T}W)+\sum_mC_m\sum_nmax(0, 1-y_n^mTr(W^{T}X_n^m))<br>\end{equation}<br>这个模型还可以扩展成Multilinear的模型<br>其他的SVM模型，如Structural SVM，也可以写成这种形式</p>
<p></p><h2>实验</h2><br>作者使用了行人检测的数据集INRIA-MOTION[1]类的数据集UCF-Sports[2]，使用的是HOG特征和流特征flow feature[1]<p></p>
<p>[1] Human detection using oriented histograms of flow and appearance<br>[2] Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Bilinear模型作为linear模型的泛化版本，一般是为了提升模型的表达能力，但是这篇文章是反过来的：作者把参数$W$分解为一些低秩矩阵，也即“因子”【factor】的积，进而减少参数数量，防止过拟合。&lt;br&gt;
    
    </summary>
    
      <category term="TransferLearning" scheme="http://yoursite.com/categories/TransferLearning/"/>
    
    
      <category term="Transfer" scheme="http://yoursite.com/tags/Transfer/"/>
    
      <category term="Bilinear" scheme="http://yoursite.com/tags/Bilinear/"/>
    
      <category term="SVM" scheme="http://yoursite.com/tags/SVM/"/>
    
      <category term="NIPS" scheme="http://yoursite.com/tags/NIPS/"/>
    
  </entry>
  
</feed>
