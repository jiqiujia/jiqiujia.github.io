<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>K_Augus</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="K_Augus">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="K_Augus">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="K_Augus">
  
    <link rel="alternate" href="/atom.xml" title="K_Augus" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">K_Augus</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Unsupervised-Learning-PaperNotes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/25/Unsupervised-Learning-PaperNotes/" class="article-date">
  <time datetime="2016-11-25T05:51:45.123Z" itemprop="datePublished">2016-11-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/11/25/Unsupervised-Learning-PaperNotes/" data-id="civxdi2oa00002gcvai8dzivf" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Auto-Encoding-Variational-Bayes-iclr14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/18/Auto-Encoding-Variational-Bayes-iclr14/" class="article-date">
  <time datetime="2016-11-18T02:16:18.000Z" itemprop="datePublished">2016-11-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/PaperNotes/">PaperNotes</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/18/Auto-Encoding-Variational-Bayes-iclr14/">Auto-Encoding Variational Bayes_iclr14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这是一篇不可多得的好文章，将无监督的深度生成模型与变分贝叶斯模型结合在一起。它包含两部分，一部分是probabilistic encoder $Q_{\Phi}(Z|X)$，用来近似真实的后验分布$P_{\Theta}(Z|X)$，将输入$X$映射到隐含层编码$Z$；另一部分是生成模型$P_{\Theta}(X|Z)$【decoder】，用隐含层的表示重构输入$X$</p>
        
          <p class="article-more-link">
            <a href="/2016/11/18/Auto-Encoding-Variational-Bayes-iclr14/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/11/18/Auto-Encoding-Variational-Bayes-iclr14/" data-id="civn6a7xz0000kgcvq6evnk18" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bayesian/">Bayesian</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DL/">DL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ICLR/">ICLR</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Depth-Map-Prediction" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/17/Depth-Map-Prediction/" class="article-date">
  <time datetime="2016-09-17T04:18:56.000Z" itemprop="datePublished">2016-09-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/PaperNotes/">PaperNotes</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/17/Depth-Map-Prediction/">Depth Map Prediction</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这篇文章主要是一些做深度图像预测的论文笔记。</p>
        
          <p class="article-more-link">
            <a href="/2016/09/17/Depth-Map-Prediction/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/17/Depth-Map-Prediction/" data-id="civn67r9r0002y0cvbapxaq5r" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DepthMap/">DepthMap</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Gaussian-distribution" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/15/Gaussian-distribution/" class="article-date">
  <time datetime="2016-09-15T14:08:26.000Z" itemprop="datePublished">2016-09-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Tutorial/">Tutorial</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/15/Gaussian-distribution/">Gaussian distribution</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这篇文章主要是讲一些常用的高斯分布的性质。那么，为什么高斯分布这么常用呢？我觉得主要有两个原因，一个是中心极限定理；第二个则是因为用高斯分布往往能得到漂亮的闭式解。</p>
        
          <p class="article-more-link">
            <a href="/2016/09/15/Gaussian-distribution/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/15/Gaussian-distribution/" data-id="civn67rac0009y0cvdviaeoat" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Gaussian/">Gaussian</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tutorial/">Tutorial</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Distilling-the-Knowledge-in-a-Neural-Network" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/11/Distilling-the-Knowledge-in-a-Neural-Network/" class="article-date">
  <time datetime="2016-09-11T12:08:49.000Z" itemprop="datePublished">2016-09-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/ModelCompression/">ModelCompression</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/11/Distilling-the-Knowledge-in-a-Neural-Network/">Distilling the Knowledge in a Neural Network</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这篇文章讲的是怎么提取训练好的模型的知识。考虑这样的场景，在很多应用场景中为了提升性能往往需要做集成，但是用集成的模型的话首先部署不够灵活，其次计算量会比较大；或者在深度学习里我们一个模型参数动则上百兆，要把这些模型部署到一些嵌入式设备也不太现实。这篇文章就是对复杂模型的输出【soft target】做一些调整，作为监督信息训练小模型。作者称之为”Knowledge Distillation”。</p>
        
          <p class="article-more-link">
            <a href="/2016/09/11/Distilling-the-Knowledge-in-a-Neural-Network/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/11/Distilling-the-Knowledge-in-a-Neural-Network/" data-id="civn67ra70006y0cv4imjgwwq" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ModelCompression/">ModelCompression</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Transfer/">Transfer</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Variational-Inference" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/10/Variational-Inference/" class="article-date">
  <time datetime="2016-09-10T14:42:01.000Z" itemprop="datePublished">2016-09-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Tutorial/">Tutorial</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/10/Variational-Inference/">Variational Inference</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2>1. 背景</h2><br>在概率模型中，我们常常需要得到隐变量的后验分布或者计算相对于某个分布的期望，比如在EM算法中我们需要得到隐变量$Z$的后验分布，以及计算完全数据的似然分布相对于隐变量的后验分布的期望。然而对于很多现实中的模型，常常因为隐变量的维度过高，难以计算；或者期望太过复杂，没有闭式解。这时候我们就要寻求近似解。近似解大体上分为两种，一种是stochastic approximation，如MCMC；另一种是deterministic approximation，比如我们这篇文章要讲的变分推断。<br><br>变分法最早来源于微积分，因为涉及到函数空间，所以叫变分。变分法的核心思想，就是从某个函数空间中找到满足某些条件或约束的函数。我们在统计推断中用到的变分法，实际上就是用形式简单的分布，去近似形式复杂、不易计算的分布，这样再做积分运算就会容易的多。<br><br>
        
          <p class="article-more-link">
            <a href="/2016/09/10/Variational-Inference/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/10/Variational-Inference/" data-id="civn67rao000iy0cvcsyy2pm5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bayesian/">Bayesian</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tutorial/">Tutorial</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Self-Paced-Learning-with-Diversity-NIPS14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/04/Self-Paced-Learning-with-Diversity-NIPS14/" class="article-date">
  <time datetime="2016-09-04T14:09:31.000Z" itemprop="datePublished">2016-09-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/SelfPacedLearning/">SelfPacedLearning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/04/Self-Paced-Learning-with-Diversity-NIPS14/">Self-Paced Learning with Diversity_NIPS14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这一篇文章的思想其实很简单，就是让SPL在选择样本的时候不单单只考虑样本的难易程度，还要考虑样本的多样性。这个多样性通过group lasso的优化项来体现。</p>
        
          <p class="article-more-link">
            <a href="/2016/09/04/Self-Paced-Learning-with-Diversity-NIPS14/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/04/Self-Paced-Learning-with-Diversity-NIPS14/" data-id="civn67ram000hy0cvh8nffzck" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NIPS/">NIPS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SelfPacedLearning/">SelfPacedLearning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Expectation-Maximization-Algorithm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/03/Expectation-Maximization-Algorithm/" class="article-date">
  <time datetime="2016-09-03T02:28:16.000Z" itemprop="datePublished">2016-09-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Tutorial/">Tutorial</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/03/Expectation-Maximization-Algorithm/">Expectation Maximization Algorithm</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在机器学习的领域里面，我们常常需要用极大似然估计【或极大化后验】的方法去做参数估计<br>\begin{equation}<br>\theta^{MLE}=argmax_{\theta}(\mathcal{L}(\theta))=argmax_{\theta}(ln[p(X|\theta)])<br>\end{equation}<br>然而，当模型中含有隐变量，或者说观测数据不完整时，用极大似然估计往往不能得到一个闭式解【closed-form solution】。EM算法就是一种求解这种含有隐变量模型的迭代算法。</p>
        
          <p class="article-more-link">
            <a href="/2016/09/03/Expectation-Maximization-Algorithm/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/03/Expectation-Maximization-Algorithm/" data-id="civn67rag000by0cvud05t2ky" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/EM/">EM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Latent/">Latent</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Tutorial/">Tutorial</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Self-Paced-Learning-for-Latent-Variable-Models-NIPS10" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/02/Self-Paced-Learning-for-Latent-Variable-Models-NIPS10/" class="article-date">
  <time datetime="2016-09-02T14:14:38.000Z" itemprop="datePublished">2016-09-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/SelfPacedLearning/">SelfPacedLearning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/02/Self-Paced-Learning-for-Latent-Variable-Models-NIPS10/">Self-Paced Learning for Latent Variable Models_NIPS10</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这一篇是Self-Paced Learning(SPL)的奠基之作。<br>SPL，固名思义，就是一步步，有自主步伐节奏得学。Motivation应该来自于09年Bengio提出的Curriculum Learning(CL)。CL受到认知科学的启发——人在学东西的时候也没办法一下子接受特别困难的知识，是从简单的开始学起。所以CL是根据某种先验，将按照困难度排好序的样本逐渐喂给模型。SPL与CL最大的不同之处在于这个排样本的先验是嵌入到模型里面的，是动态的，可以优化学习的。<br>这样子从易到难得学可以看成是一种正则化的手段，有助于加快收敛，并达到一个更好的local minimum.</p>
        
          <p class="article-more-link">
            <a href="/2016/09/02/Self-Paced-Learning-for-Latent-Variable-Models-NIPS10/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/02/Self-Paced-Learning-for-Latent-Variable-Models-NIPS10/" data-id="civn67raj000dy0cvv6758d9c" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Latent/">Latent</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NIPS/">NIPS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SelfPacedLearning/">SelfPacedLearning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Domain-Adaptation-from-Multiple-Sources-via-Auxiliary-Classifiers-ICML09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/01/Domain-Adaptation-from-Multiple-Sources-via-Auxiliary-Classifiers-ICML09/" class="article-date">
  <time datetime="2016-09-01T02:51:42.000Z" itemprop="datePublished">2016-09-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/TransferLearning/">TransferLearning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/01/Domain-Adaptation-from-Multiple-Sources-via-Auxiliary-Classifiers-ICML09/">Domain Adaptation from Multiple Sources via Auxiliary Classifiers_ICML09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这篇文章做的是从多个源领域到单个目标领域的迁移，思想来源于Adaptive SVM[1]，就是使源领域模型参数“适应”到目标领域去。<br>
        
          <p class="article-more-link">
            <a href="/2016/09/01/Domain-Adaptation-from-Multiple-Sources-via-Auxiliary-Classifiers-ICML09/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/01/Domain-Adaptation-from-Multiple-Sources-via-Auxiliary-Classifiers-ICML09/" data-id="civn67ra90007y0cv4otgiotk" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ICML/">ICML</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SVM/">SVM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Transfer/">Transfer</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/ModelCompression/">ModelCompression</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PaperNotes/">PaperNotes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/SelfPacedLearning/">SelfPacedLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/TransferLearning/">TransferLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tutorial/">Tutorial</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayesian/">Bayesian</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bilinear/">Bilinear</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DL/">DL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DepthMap/">DepthMap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EM/">EM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gaussian/">Gaussian</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICLR/">ICLR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICML/">ICML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Latent/">Latent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ModelCompression/">ModelCompression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NIPS/">NIPS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SelfPacedLearning/">SelfPacedLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Transfer/">Transfer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tutorial/">Tutorial</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Bayesian/" style="font-size: 15px;">Bayesian</a> <a href="/tags/Bilinear/" style="font-size: 10px;">Bilinear</a> <a href="/tags/DL/" style="font-size: 10px;">DL</a> <a href="/tags/DepthMap/" style="font-size: 10px;">DepthMap</a> <a href="/tags/EM/" style="font-size: 10px;">EM</a> <a href="/tags/Gaussian/" style="font-size: 10px;">Gaussian</a> <a href="/tags/ICLR/" style="font-size: 10px;">ICLR</a> <a href="/tags/ICML/" style="font-size: 10px;">ICML</a> <a href="/tags/Latent/" style="font-size: 15px;">Latent</a> <a href="/tags/ModelCompression/" style="font-size: 10px;">ModelCompression</a> <a href="/tags/NIPS/" style="font-size: 20px;">NIPS</a> <a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/SelfPacedLearning/" style="font-size: 15px;">SelfPacedLearning</a> <a href="/tags/Transfer/" style="font-size: 20px;">Transfer</a> <a href="/tags/Tutorial/" style="font-size: 20px;">Tutorial</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/11/25/Unsupervised-Learning-PaperNotes/">(no title)</a>
          </li>
        
          <li>
            <a href="/2016/11/18/Auto-Encoding-Variational-Bayes-iclr14/">Auto-Encoding Variational Bayes_iclr14</a>
          </li>
        
          <li>
            <a href="/2016/09/17/Depth-Map-Prediction/">Depth Map Prediction</a>
          </li>
        
          <li>
            <a href="/2016/09/15/Gaussian-distribution/">Gaussian distribution</a>
          </li>
        
          <li>
            <a href="/2016/09/11/Distilling-the-Knowledge-in-a-Neural-Network/">Distilling the Knowledge in a Neural Network</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 K_Augus<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>